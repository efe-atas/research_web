<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="A comprehensive study on Wallpaper Symmetry Group Learning comparing Standard Autoencoders and Beta Variational Autoencoders (β-VAE) with different beta values.">
  <meta name="keywords"
    content="Autoencoder, β-VAE, VAE, Symmetry Learning, Wallpaper Groups, Disentanglement, Deep Learning, Latent Space">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Autoencoder vs β-VAE for Wallpaper Symmetry Learning</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="index.html">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            Experiments
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="standard-ae.html">
              Standard Autoencoder (Best Reconstruction)
            </a>
            <a class="navbar-item" href="beta-05.html">
              β = 0.5 (Reconstruction Focus)
            </a>
            <a class="navbar-item" href="beta-10.html">
              β = 1.0 (Standard VAE)
            </a>
            <a class="navbar-item" href="beta-40.html">
              β = 4.0 (Disentanglement Focus)
            </a>
            <a class="navbar-item" href="comparison.html">
              Comparative Analysis
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Wallpaper Symmetry Group Learning: A Comparative Study of Standard
              Autoencoders and β-VAE</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                İsmail Efe Ataş<br>
                <span class="author-block">
                  TED University<br>
                  Department of Computer Engineering<br>
                  <a href="mailto:efeatas@itu.edu.tr">iefeatas@gmail.com</a>
                </span>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">Research Project</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="./sources/standart_autoencoder/" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->
                <span class="link-block">
                  <a href="https://zenodo.org/records/7384734" class="external-link button is-normal is-rounded is-dark"
                    target="_blank">
                    <span class="icon">
                      <i class="far fa-images"></i>
                    </span>
                    <span>Dataset (Zenodo)</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>




  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              This research presents a comprehensive comparative study between <strong>Standard Convolutional
                Autoencoders</strong>
              and <strong>Beta Variational Autoencoders (β-VAE)</strong> for the learning and analysis of
              <strong>17 wallpaper symmetry groups</strong>. Wallpaper groups represent all possible ways to repeat
              a pattern in two dimensions and have applications in crystallography, materials science, and computer
              graphics.
            </p>
            <p>
              We compare <strong>four different model configurations</strong>: a deterministic Standard Autoencoder
              (no KL regularization), and three β-VAE variants with β values of 0.5, 1.0, and 4.0. This allows us
              to systematically investigate how probabilistic modeling and the strength of latent regularization
              affect reconstruction quality, latent space organization, and class separability.
            </p>
            <p>
              Our experiments utilize the <strong><a href="https://zenodo.org/records/7384734" target="_blank">Symmetry
                  Dataset</a></strong>
              (Guo & Agar, 2022) from Zenodo, comprising <strong>76,500 training samples</strong>,
              <strong>8,500 validation samples</strong>, and <strong>355 test samples</strong> across all 17 symmetry
              classes.
              Key findings reveal that the <strong>Standard Autoencoder achieves the best reconstruction
                quality</strong>
              (Test MSE: 0.061), while <strong>β-VAE with β=4.0 produces the most regularized latent space</strong>
              (KL Divergence: 2.64). The standard VAE (β=1.0) offers the most compact representations with
              64.47% PCA explained variance in just 2 dimensions.
            </p>
            <p>
              We provide detailed analysis including t-SNE/PCA visualizations, latent space statistics, error
              distributions,
              class-wise reconstruction errors, and comprehensive training dynamics. Our findings offer practical
              guidance
              for selecting the appropriate model architecture based on specific application requirements.
            </p>
          </div>
        </div>
      </div>
      <!--/ Abstract. -->

      <!-- Model Configuration. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Model Architectures & Configurations</h2>
          <div class="content has-text-justified">
            <p>
              We evaluate two fundamental autoencoder paradigms: the <strong>deterministic Standard Autoencoder</strong>
              and the <strong>probabilistic Variational Autoencoder</strong>. Both use similar convolutional
              architectures
              but differ in their latent space formulation.
            </p>
            <div class="box">
              <h4>Standard Autoencoder Loss:</h4>
              <p style="text-align: center; font-size: 1.2em;">
                <strong>L = MSE(x, x̂)</strong>
              </p>
              <h4>β-VAE Loss:</h4>
              <p style="text-align: center; font-size: 1.2em;">
                <strong>L = MSE(x, x̂) + β × KL(q(z|x) || N(0, I))</strong>
              </p>
            </div>
          </div>
          <div class="content">
            <table class="table is-striped is-fullwidth">
              <thead>
                <tr>
                  <th>Parameter</th>
                  <th>Standard AE</th>
                  <th>β-VAE</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <td>Model Type</td>
                  <td>Convolutional Autoencoder</td>
                  <td>Beta Variational Autoencoder</td>
                </tr>
                <tr>
                  <td>Input Size</td>
                  <td colspan="2">256×256×3 (RGB)</td>
                </tr>
                <tr>
                  <td>Parameters</td>
                  <td>464,739</td>
                  <td>464,931</td>
                </tr>
                <tr>
                  <td>Latent Dimensions</td>
                  <td>16,384 (flattened 16×16×64)</td>
                  <td>64 (μ, σ parameterized)</td>
                </tr>
                <tr>
                  <td>Base Channels</td>
                  <td colspan="2">32</td>
                </tr>
                <tr>
                  <td>Total Parameters</td>
                  <td>464,739</td>
                  <td>464,931</td>
                </tr>
                <tr>
                  <td>Encoder</td>
                  <td colspan="2">Conv2d + BatchNorm + LeakyReLU (4 blocks)</td>
                </tr>
                <tr>
                  <td>Decoder</td>
                  <td colspan="2">ConvTranspose2d + BatchNorm + ReLU (4 blocks)</td>
                </tr>
                <tr>
                  <td>Final Activation</td>
                  <td colspan="2">Tanh</td>
                </tr>
                <tr>
                  <td>Learning Rate</td>
                  <td colspan="2">0.001</td>
                </tr>
                <tr>
                  <td>Optimizer</td>
                  <td>AdamW</td>
                  <td>Adam</td>
                </tr>
                <tr>
                  <td>Scheduler</td>
                  <td>CosineAnnealingLR</td>
                  <td>-</td>
                </tr>
                <tr>
                  <td>Batch Size</td>
                  <td colspan="2">32</td>
                </tr>
                <tr>
                  <td>Early Stopping</td>
                  <td colspan="2">Patience = 5</td>
                </tr>
                <tr>
                  <td>Training Samples</td>
                  <td colspan="2">76,500</td>
                </tr>
                <tr>
                  <td>Validation Samples</td>
                  <td colspan="2">8,500</td>
                </tr>
                <tr>
                  <td>Test Samples</td>
                  <td colspan="2">355</td>
                </tr>
                <tr>
                  <td>Number of Classes</td>
                  <td colspan="2">17 wallpaper symmetry groups</td>
                </tr>
              </tbody>
            </table>
          </div>
        </div>
      </div>
      <!--/ Model Configuration. -->
    </div>
  </section>

  <!-- ==================== EXPERIMENT LINKS SECTION ==================== -->
  <section class="section" style="background-color: #f5f5f5;">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Experiment Results</h2>
      <p class="has-text-centered mb-5">Click on any experiment to view detailed results and analysis.</p>

      <div class="columns is-multiline">
        <div class="column is-half">
          <a href="standard-ae.html" class="box" style="border-left: 4px solid #7c4dff; display: block;">
            <h4 class="title is-5" style="color: #7c4dff;">Standard Autoencoder</h4>
            <p><strong>Best Reconstruction Quality</strong></p>
            <ul>
              <li>Test MSE: <strong>0.061</strong> (lowest)</li>
              <li>Training Time: 1h 8min (fastest)</li>
              <li>Latent Dim: 16,384</li>
            </ul>
          </a>
        </div>
        <div class="column is-half">
          <a href="beta-05.html" class="box" style="border-left: 4px solid #3273dc; display: block;">
            <h4 class="title is-5" style="color: #3273dc;">β-VAE (β = 0.5)</h4>
            <p><strong>Reconstruction Focus</strong></p>
            <ul>
              <li>Test VAE Loss: 0.129</li>
              <li>Best VAE reconstruction</li>
              <li>KL Divergence: 9.79</li>
            </ul>
          </a>
        </div>
        <div class="column is-half">
          <a href="beta-10.html" class="box" style="border-left: 4px solid #48c774; display: block;">
            <h4 class="title is-5" style="color: #48c774;">β-VAE (β = 1.0)</h4>
            <p><strong>Standard VAE (Balanced)</strong></p>
            <ul>
              <li>Test VAE Loss: 0.155</li>
              <li>PCA Variance: <strong>64.47%</strong> (highest)</li>
              <li>Most compact representations</li>
            </ul>
          </a>
        </div>
        <div class="column is-half">
          <a href="beta-40.html" class="box" style="border-left: 4px solid #ff3860; display: block;">
            <h4 class="title is-5" style="color: #ff3860;">β-VAE (β = 4.0)</h4>
            <p><strong>Disentanglement Focus</strong></p>
            <ul>
              <li>Test VAE Loss: 0.233</li>
              <li>KL Divergence: <strong>2.64</strong> (lowest)</li>
              <li>Best latent regularization</li>
            </ul>
          </a>
        </div>
      </div>

      <div class="has-text-centered mt-5">
        <a href="comparison.html" class="button is-dark is-large">
          <span class="icon"><i class="fas fa-chart-bar"></i></span>
          <span>View Comprehensive Comparative Analysis</span>
        </a>
      </div>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="./sources/standart_autoencoder/">
          <i class="fas fa-file-code"></i>
        </a>
        <a class="icon-link" href="#">
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              Template adapted from the <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> project page.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>