# beta = 4.0

`{
  "train_root": "/content/symmetry_dataset",
  "test_root": "/content/test",
  "output_dir": "/content/artifacts",
  "image_size": [
    256,
    256
  ],
  "num_channels": 3,
  "normalize": true,
  "batch_size": 32,
  "num_workers": 0,
  "pin_memory": true,
  "val_split": 0.1,
  "epochs": 30,
  "learning_rate": 0.001,
  "weight_decay": 1e-05,
  "max_grad_norm": 5.0,
  "patience": 5,
  "max_train_samples": 85000,
  "max_test_samples": null,
  "latent_channels": 64,
  "base_channels": 32,
  "seed": 42,
  "beta": 4.0,
  "in_channels": 3,
  "normalize_mean": [
    0.5,
    0.5,
    0.5
  ],
  "normalize_std": [
    0.5,
    0.5,
    0.5
  ]
}`

Training samples: 76500
Validation samples: 8500
Test samples: 355
Number of classes: 17

![image.png](beta%20=%204%200/image.png)

Model parameters: 464,931

`Epoch 1: loss=0.113903 (recon=0.064053, Î²Ã—kld=0.049851) | val_loss=0.061474`

`Epoch 2: loss=0.079156 (recon=0.059622, Î²Ã—kld=0.019534) | val_loss=0.060015`

`Epoch 3: loss=0.071709 (recon=0.052876, Î²Ã—kld=0.018833) | val_loss=0.058703`

`Epoch 4: loss=0.069360 (recon=0.050404, Î²Ã—kld=0.018956) | val_loss=0.057971`

`Epoch 5: loss=0.068417 (recon=0.049371, Î²Ã—kld=0.019046) | val_loss=0.056790`

`Epoch 6: loss=0.067460 (recon=0.048332, Î²Ã—kld=0.019128) | val_loss=0.057376`

`Epoch 7: loss=0.066969 (recon=0.047791, Î²Ã—kld=0.019179) | val_loss=0.056560`

`Epoch 8: loss=0.066316 (recon=0.047152, Î²Ã—kld=0.019164) | val_loss=0.056259`

`Epoch 9: loss=0.065868 (recon=0.046675, Î²Ã—kld=0.019193) | val_loss=0.056904`

`Epoch 10: loss=0.065450 (recon=0.046287, Î²Ã—kld=0.019163) | val_loss=0.057071`

`Epoch 11: loss=0.065182 (recon=0.046008, Î²Ã—kld=0.019174) | val_loss=0.056172`

`Epoch 12: loss=0.064809 (recon=0.045599, Î²Ã—kld=0.019210) | val_loss=0.056114`

`Epoch 13: loss=0.064248 (recon=0.045081, Î²Ã—kld=0.019168) | val_loss=0.056488`

`Epoch 14: loss=0.063840 (recon=0.044728, Î²Ã—kld=0.019112) | val_loss=0.056277`

`Epoch 15: loss=0.063369 (recon=0.044236, Î²Ã—kld=0.019133) | val_loss=0.056368`

`Epoch 16: loss=0.063083 (recon=0.043950, Î²Ã—kld=0.019132) | val_loss=0.056197`

`Epoch 17: loss=0.062857 (recon=0.043761, Î²Ã—kld=0.019096) | val_loss=0.055758`

`Epoch 18: loss=0.062734 (recon=0.043618, Î²Ã—kld=0.019117) | val_loss=0.055796`

`Epoch 19: loss=0.062506 (recon=0.043362, Î²Ã—kld=0.019144) | val_loss=0.055642`

`Epoch 20: loss=0.062415 (recon=0.043289, Î²Ã—kld=0.019126) | val_loss=0.055471`

`Epoch 21: loss=0.062230 (recon=0.043085, Î²Ã—kld=0.019146) | val_loss=0.055632`

`Epoch 22: loss=0.062169 (recon=0.043032, Î²Ã—kld=0.019137) | val_loss=0.056093`

`Epoch 23: loss=0.062106 (recon=0.042956, Î²Ã—kld=0.019150) | val_loss=0.055899`

`Epoch 24: loss=0.062021 (recon=0.042885, Î²Ã—kld=0.019136) | val_loss=0.055734`

`Epoch 25: loss=0.061914 (recon=0.042766, Î²Ã—kld=0.019148) | val_loss=0.055626
Early stopping triggered.
CPU times: user 6h 44min 34s, sys: 2min 30s, total: 6h 47min 4s
Wall time: 2h 25min`

Best model loaded (epoch=20, val_loss=0.055470749101218055)

![image.png](beta%20=%204%200/image%201.png)

![image.png](beta%20=%204%200/image%202.png)

![image.png](beta%20=%204%200/image%203.png)

![image.png](beta%20=%204%200/image%204.png)

![image.png](beta%20=%204%200/image%205.png)

![image.png](beta%20=%204%200/image%206.png)

![image.png](beta%20=%204%200/image%207.png)

# ============================================================
LATENT SPACE STATISTICS

# Total latent dimensions: 64
Î¼ - Mean: 0.0002, Std: 0.1568
Ïƒ - Mean: 0.9625, Std: 0.1321
Total KL Divergence (per sample): 2.6418

![image.png](beta%20=%204%200/image%208.png)

![image.png](beta%20=%204%200/image%209.png)

![image.png](beta%20=%204%200/image%2010.png)

![image.png](beta%20=%204%200/image%2011.png)

![image.png](beta%20=%204%200/image%2012.png)

![image.png](beta%20=%204%200/image%2013.png)

`Test VAE loss: 0.233418

Class-wise reconstruction error (mean Â± std):
- p1: 0.123446 Â± 0.083985
- pm: 0.142585 Â± 0.105203
- pmg: 0.148993 Â± 0.077063
- cm: 0.154031 Â± 0.090775
- p3m1: 0.166798 Â± 0.095644
- p3: 0.186465 Â± 0.117631
- p31m: 0.199842 Â± 0.102951
- cmm: 0.202920 Â± 0.152224
- p2: 0.203061 Â± 0.149593
- pmm: 0.210347 Â± 0.141215
- p4g: 0.213531 Â± 0.113930
- p4m: 0.224520 Â± 0.091918
- pg: 0.224819 Â± 0.162026
- pgg: 0.233071 Â± 0.187933
- p6m: 0.240179 Â± 0.135868
- p4: 0.261148 Â± 0.176462
- p6: 0.301155 Â± 0.155425`

![image.png](beta%20=%204%200/image%2014.png)

![image.png](beta%20=%204%200/image%2015.png)

`======================================================================
               Î²-VAE MODEL REPORT - SYMMETRY CLASSIFICATION
======================================================================

ðŸ“Š MODEL CONFIGURATION
----------------------------------------------------------------------
  â€¢ Model Type:           Beta Variational Autoencoder (Î²-VAE)
  â€¢ Beta (Î²) Value:       4.0
  â€¢ Image Size:           256x256
  â€¢ Num Channels:         3
  â€¢ Latent Channels:      64
  â€¢ Base Channels:        32
  â€¢ Parameters:           464,931

ðŸ“ˆ TRAINING INFO
----------------------------------------------------------------------
  â€¢ Training Samples:     76,500
  â€¢ Validation Samples:   8,500
  â€¢ Test Samples:         355
  â€¢ Num Classes:          17
  â€¢ Num Epochs:           25
  â€¢ Learning Rate:        0.001
  â€¢ Batch Size:           32

ðŸ“‰ TRAINING RESULTS
----------------------------------------------------------------------
  â€¢ Final Train Loss:     0.061914
  â€¢ Final Recon Loss:     0.042766
  â€¢ Final KL Loss:        0.004787
  â€¢ Final Val Loss:       0.055626

ðŸŽ¯ TEST PERFORMANCE
----------------------------------------------------------------------
  â€¢ Test VAE Loss:        0.233418
  â€¢ Best Class:           p1 (MSE: 0.123446)
  â€¢ Worst Class:          p6 (MSE: 0.301155)

ðŸ”¬ LATENT SPACE ANALYSIS
----------------------------------------------------------------------
  â€¢ Total Latent Dims:    64
  â€¢ Î¼ Mean:               0.0002 (Ideal: 0)
  â€¢ Î¼ Std:                0.1568
  â€¢ Ïƒ Mean:               0.9625 (Ideal: 1)
  â€¢ Ïƒ Std:                0.1321
  â€¢ Avg KL Divergence:    2.6418

ðŸ’¡ Î²-VAE INTERPRETATION
----------------------------------------------------------------------
  Î² = 4.0 > 1: Model prioritizes disentanglement.
  This leads to latent dimensions learning more independent features,
  but reconstruction quality may decrease.

======================================================================
                         END OF REPORT
======================================================================

ðŸ“„ Report saved: /content/artifacts/beta_vae_report.txt`