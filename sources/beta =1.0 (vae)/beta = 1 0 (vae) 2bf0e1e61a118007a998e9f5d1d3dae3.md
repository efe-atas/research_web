# beta = 1.0 (vae)

`{
  "train_root": "/content/symmetry_dataset",
  "test_root": "/content/test",
  "output_dir": "/content/artifacts",
  "image_size": [
    256,
    256
  ],
  "num_channels": 3,
  "normalize": true,
  "batch_size": 32,
  "num_workers": 0,
  "pin_memory": true,
  "val_split": 0.1,
  "epochs": 30,
  "learning_rate": 0.001,
  "weight_decay": 1e-05,
  "max_grad_norm": 5.0,
  "patience": 5,
  "max_train_samples": 85000,
  "max_test_samples": null,
  "latent_channels": 64,
  "base_channels": 32,
  "seed": 42,
  "beta": 1,
  "in_channels": 3,
  "normalize_mean": [
    0.5,
    0.5,
    0.5
  ],
  "normalize_std": [
    0.5,
    0.5,
    0.5
  ]
}`

Training samples: 76500
Validation samples: 8500
Test samples: 355
Number of classes: 17

![image.png](beta%20=%201%200%20(vae)/image.png)

Model parameters: 464,931

`Epoch 1: loss=0.070950 (recon=0.051767, Î²Ã—kld=0.019183) | val_loss=0.046682`

`Epoch 2: loss=0.053259 (recon=0.040093, Î²Ã—kld=0.013166) | val_loss=0.041148`

`Epoch 3: loss=0.049130 (recon=0.036101, Î²Ã—kld=0.013029) | val_loss=0.040304`

`Epoch 4: loss=0.047098 (recon=0.034061, Î²Ã—kld=0.013037) | val_loss=0.038115`

`Epoch 5: loss=0.045720 (recon=0.032753, Î²Ã—kld=0.012967) | val_loss=0.037220`

`Epoch 6: loss=0.044973 (recon=0.032069, Î²Ã—kld=0.012904) | val_loss=0.036555`

`Epoch 7: loss=0.044105 (recon=0.031246, Î²Ã—kld=0.012859) | val_loss=0.036297`

`Epoch 8: loss=0.043683 (recon=0.030854, Î²Ã—kld=0.012829) | val_loss=0.036556`

`Epoch 9: loss=0.043423 (recon=0.030603, Î²Ã—kld=0.012820) | val_loss=0.036116`

`Epoch 10: loss=0.043059 (recon=0.030252, Î²Ã—kld=0.012807) | val_loss=0.035840`

`Epoch 11: loss=0.042621 (recon=0.029822, Î²Ã—kld=0.012798) | val_loss=0.035762`

`Epoch 12: loss=0.042392 (recon=0.029601, Î²Ã—kld=0.012791) | val_loss=0.035304`

`Epoch 13: loss=0.042186 (recon=0.029386, Î²Ã—kld=0.012799) | val_loss=0.035609`

`Epoch 14: loss=0.042039 (recon=0.029272, Î²Ã—kld=0.012767) | val_loss=0.036140`

`Epoch 15: loss=0.041674 (recon=0.028910, Î²Ã—kld=0.012764) | val_loss=0.035059`

`Epoch 16: loss=0.041630 (recon=0.028868, Î²Ã—kld=0.012763) | val_loss=0.035002`

`Epoch 17: loss=0.041352 (recon=0.028585, Î²Ã—kld=0.012766) | val_loss=0.035384`

`Epoch 18: loss=0.041263 (recon=0.028515, Î²Ã—kld=0.012748) | val_loss=0.034803`

`Epoch 19: loss=0.041101 (recon=0.028362, Î²Ã—kld=0.012738) | val_loss=0.035628`

`Epoch 20: loss=0.040939 (recon=0.028202, Î²Ã—kld=0.012737) | val_loss=0.034617`

`Epoch 21: loss=0.040806 (recon=0.028075, Î²Ã—kld=0.012731) | val_loss=0.034647`

`Epoch 22: loss=0.040689 (recon=0.027962, Î²Ã—kld=0.012727) | val_loss=0.034945`

`Epoch 23: loss=0.040613 (recon=0.027895, Î²Ã—kld=0.012718) | val_loss=0.034793`

`Epoch 24: loss=0.040497 (recon=0.027792, Î²Ã—kld=0.012705) | val_loss=0.034745`

`Epoch 25: loss=0.040380 (recon=0.027668, Î²Ã—kld=0.012711) | val_loss=0.034589`

`Epoch 26: loss=0.040296 (recon=0.027602, Î²Ã—kld=0.012694) | val_loss=0.034605`

`Epoch 27: loss=0.040328 (recon=0.027621, Î²Ã—kld=0.012707) | val_loss=0.034778`

`Epoch 28: loss=0.040257 (recon=0.027556, Î²Ã—kld=0.012700) | val_loss=0.034742`

`Epoch 29: loss=0.040211 (recon=0.027506, Î²Ã—kld=0.012705) | val_loss=0.034869`

`Epoch 30: loss=0.040207 (recon=0.027504, Î²Ã—kld=0.012703) | val_loss=0.034520
CPU times: user 7h 39min 33s, sys: 3min 6s, total: 7h 42min 40s
Wall time: 2h 49min 52s`

Best model loaded (epoch=30, val_loss=0.03451974942754297)

![image.png](beta%20=%201%200%20(vae)/image%201.png)

![image.png](beta%20=%201%200%20(vae)/image%202.png)

Latent shape: (1000, 64)

- -- PCA Visualization ---
Computing PCA... (data shape: (1000, 64))
PCA completed (explained variance: 64.47%)

![image.png](beta%20=%201%200%20(vae)/image%203.png)

![image.png](beta%20=%201%200%20(vae)/image%204.png)

![image.png](beta%20=%201%200%20(vae)/image%205.png)

![image.png](beta%20=%201%200%20(vae)/image%206.png)

# ============================================================
LATENT SPACE STATISTICS

# Total latent dimensions: 64
Î¼ - Mean: -0.0009, Std: 0.2010
Ïƒ - Mean: 0.9042, Std: 0.1983
Total KL Divergence (per sample): 6.2983

![image.png](beta%20=%201%200%20(vae)/image%207.png)

![image.png](beta%20=%201%200%20(vae)/image%208.png)

![image.png](beta%20=%201%200%20(vae)/image%209.png)

![image.png](beta%20=%201%200%20(vae)/image%2010.png)

![image.png](beta%20=%201%200%20(vae)/image%2011.png)

![image.png](beta%20=%201%200%20(vae)/image%2012.png)

`Test VAE loss: 0.155442

Class-wise reconstruction error (mean Â± std):
- p1: 0.070367 Â± 0.055601
- pm: 0.088343 Â± 0.074099
- cm: 0.089018 Â± 0.059490
- pmg: 0.096758 Â± 0.063404
- p3m1: 0.101526 Â± 0.066394
- p3: 0.113996 Â± 0.081382
- p31m: 0.121127 Â± 0.066045
- p2: 0.125733 Â± 0.097608
- p4m: 0.128415 Â± 0.054793
- cmm: 0.128547 Â± 0.124025
- pg: 0.134883 Â± 0.108223
- p4g: 0.137333 Â± 0.094188
- pmm: 0.142475 Â± 0.104441
- pgg: 0.158648 Â± 0.154222
- p6m: 0.167456 Â± 0.118347
- p4: 0.180626 Â± 0.166072
- p6: 0.193823 Â± 0.142434`

![image.png](beta%20=%201%200%20(vae)/image%2013.png)

![image.png](beta%20=%201%200%20(vae)/image%2014.png)

`======================================================================
               Î²-VAE MODEL REPORT - SYMMETRY CLASSIFICATION
======================================================================

ðŸ“Š MODEL CONFIGURATION
----------------------------------------------------------------------
  â€¢ Model Type:           Beta Variational Autoencoder (Î²-VAE)
  â€¢ Beta (Î²) Value:       1
  â€¢ Image Size:           256x256
  â€¢ Num Channels:         3
  â€¢ Latent Channels:      64
  â€¢ Base Channels:        32
  â€¢ Parameters:           464,931

ðŸ“ˆ TRAINING INFO
----------------------------------------------------------------------
  â€¢ Training Samples:     76,500
  â€¢ Validation Samples:   8,500
  â€¢ Test Samples:         355
  â€¢ Num Classes:          17
  â€¢ Num Epochs:           30
  â€¢ Learning Rate:        0.001
  â€¢ Batch Size:           32

ðŸ“‰ TRAINING RESULTS
----------------------------------------------------------------------
  â€¢ Final Train Loss:     0.040207
  â€¢ Final Recon Loss:     0.027504
  â€¢ Final KL Loss:        0.012703
  â€¢ Final Val Loss:       0.034520

ðŸŽ¯ TEST PERFORMANCE
----------------------------------------------------------------------
  â€¢ Test VAE Loss:        0.155442
  â€¢ Best Class:           p1 (MSE: 0.070367)
  â€¢ Worst Class:          p6 (MSE: 0.193823)

ðŸ”¬ LATENT SPACE ANALYSIS
----------------------------------------------------------------------
  â€¢ Total Latent Dims:    64
  â€¢ Î¼ Mean:               -0.0009 (Ideal: 0)
  â€¢ Î¼ Std:                0.2010
  â€¢ Ïƒ Mean:               0.9042 (Ideal: 1)
  â€¢ Ïƒ Std:                0.1983
  â€¢ Avg KL Divergence:    6.2983

ðŸ’¡ Î²-VAE INTERPRETATION
----------------------------------------------------------------------
  Î² = 1.0: Standard VAE behavior. Reconstruction and
  latent regularization are balanced.

======================================================================
                         END OF REPORT
======================================================================

ðŸ“„ Report saved: /content/artifacts/beta_vae_report.txt`